<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Scott Graham" />

<meta name="date" content="2017-10-06" />

<title>Week 04 Questions</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 54px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 59px;
  margin-top: -59px;
}

.section h2 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h3 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h4 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h5 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h6 {
  padding-top: 59px;
  margin-top: -59px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">STAT 541 Questions</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../../index.php">Home</a>
</li>
<li>
  <a href="Week_01_Questions.html">Week 01</a>
</li>
<li>
  <a href="Week_02_Questions.html">Week 02</a>
</li>
<li>
  <a href="Week_03_Questions.html">Week 03</a>
</li>
<li>
  <a href="Week_04_Questions.html">Week 04</a>
</li>
<li>
  <a href="Week_05_Questions.html">Week 05</a>
</li>
<li>
  <a href="Week_06_Questions.html">Week 06</a>
</li>
<li>
  <a href="Week_07_Questions.html">Week 07</a>
</li>
<li>
  <a href="Week_08_Questions.html">Week 08</a>
</li>
<li>
  <a href="Week_09_Questions.html">Week 09</a>
</li>
<li>
  <a href="Week_10_Questions.html">Week 10</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Week 04 Questions</h1>
<h4 class="author"><em>Scott Graham</em></h4>
<h4 class="date"><em>October 06, 2017</em></h4>

</div>


<p><span class="math display">\[
  \newcommand{\Prob}{\operatorname{P}}
  \newcommand{\E}{\operatorname{E}}
  \newcommand{\Var}{\operatorname{Var}}
  \newcommand{\Cov}{\operatorname{Cov}}
  \newcommand{\se}{\operatorname{se}}
  \newcommand{\re}{\operatorname{re}}
  \newcommand{\ybar}{{\overline{Y}}}
  \newcommand{\phat}{{\hat{p}}}
  \newcommand{\that}{{\hat{T}}}
  \newcommand{\med}{{\tilde{Y}}}
\]</span></p>
<div id="section" class="section level2">
<h2>3.11</h2>
<div id="a." class="section level3">
<h3>a.</h3>
<p><span class="math display">\[
  \ln\left( \mu \right) =
  \alpha + \beta x \implies
  \begin{cases}
    \stackrel{x=1}{\implies}
    \ln\left( \mu_{B} \right) =
    \alpha + \beta \\
    \stackrel{x=0}{\implies}
    \ln\left( \mu_{A} \right) =
    \alpha
  \end{cases} \implies
  \ln\left( \mu_{B} \right) - \beta =
  \ln\left( \mu_{A} \right) \implies
\]</span> <span class="math display">\[
  \beta =
  \ln\left( \mu_{B} \right) - \ln\left( \mu_{A} \right) =
  \ln\left( \frac{\mu_{B}}{\mu_{A}} \right) \implies
  e^{\beta} =
  \frac{\mu_{B}}{\mu_{A}}
\]</span></p>
</div>
<div id="b." class="section level3">
<h3>b.</h3>
<pre class="r"><code>poiss_reg_imperfection &lt;- 
  waifer_imperfections %&gt;% 
  glm(Imperfections ~ Treatment, data = ., family = poisson)
summary(poiss_reg_imperfection)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Imperfections ~ Treatment, family = poisson, data = .)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5280  -0.7622  -0.1699   0.6938   1.5399  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   1.6094     0.1414  11.380  &lt; 2e-16 ***
## TreatmentB    0.5878     0.1764   3.332 0.000861 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 27.857  on 19  degrees of freedom
## Residual deviance: 16.268  on 18  degrees of freedom
## AIC: 94.349
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p><span class="math display">\[
  \ln\left( \mu \right) =
  1.6094 + 0.5878x \implies
  \mu = 4.99981(1.800024)^{x}
\]</span> That is, on average for as you move from treatment A to B, <span class="math inline">\(\ln\left( \mu \right)\)</span> increases by 0.5878, or the mean number of imperfections increases by a multiplicative factor of 1.800024, based on the sample.</p>
</div>
<div id="c." class="section level3">
<h3>c.</h3>
<p>From above, we have a Wald P-Value of <span class="math inline">\(0.000861 &lt; \alpha = 0.05\)</span>, and therefore reject the null hypothesis of equal means, based on the sample, and accept that there is a difference in means between the two treatments.</p>
</div>
<div id="d." class="section level3">
<h3>d.</h3>
<pre class="r"><code>poiss_reg_imperfection %&gt;% 
  confint(parm = &quot;TreatmentB&quot;, level = 0.95) %&gt;% 
  exp</code></pre>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##    2.5 %   97.5 % 
## 1.280063 2.560228</code></pre>
<p>That is, based on the sample, with 95% confidence, the true value of <span class="math inline">\(\frac{\mu_{B}}{\mu_{A}}\)</span> lies somewhere between 1.28 and 2.56.</p>
</div>
</div>
<div id="section-1" class="section level2">
<h2>3.15</h2>
<div id="a.-1" class="section level3">
<h3>a.</h3>
<p><span class="math display">\[
  \hat{\mu}_{1} = 
  e^{-2.38+1.733(1)} =
  e^{-0.657} =
  0.5236
\]</span> <span class="math display">\[
  \hat{\mu}_{2} = 
  e^{-2.38+1.733(0)} =
  e^{-2.38} =
  0.0925
\]</span></p>
</div>
<div id="b.-1" class="section level3">
<h3>b.</h3>
<p>95% CI for <span class="math inline">\(\mu_{1}/\mu_{2}\)</span>: <span class="math display">\[
  e^{\hat{\beta}\mp z_{0.975}\se\left(\hat{\beta}\right)}
\]</span></p>
<pre class="r"><code>exp(1.733+qnorm(0.975)*0.147*c(-1, 1))</code></pre>
<pre><code>## [1] 4.241366 7.546733</code></pre>
</div>
<div id="c.-1" class="section level3">
<h3>c.</h3>
<p>The negative binomial model appears to be more believable. This is because we’d expect <span class="math inline">\(\mu_i={\sigma_{i}}^{2}\)</span>, which may be true for whites, but definitely doe not hold for blacks.</p>
</div>
<div id="d.-1" class="section level3">
<h3>d.</h3>
<p>If the Poisson model were appropriate, we’d expect to see <span class="math inline">\(\hat{D}\approx 0\)</span>, but instead we observe a value of 4.94. Since 0 is close to 5 standard deviations away from the estimate, it’d be extremely unlikely this value is merely an outlier.</p>
</div>
</div>
<div id="section-2" class="section level2">
<h2>3.19</h2>
<div id="a.-2" class="section level3">
<h3>a.</h3>
<pre class="r"><code>train_collisions %&lt;&gt;%
  mutate(
    Collisions_Total = Collisions + Road_Collisions
    ,Rate = (Collisions + Road_Collisions)/Km
    ,Year_base = Year-min(Year)
  )
poiss_reg_train &lt;- suppressWarnings(
  train_collisions %&gt;% 
  glm(Rate ~ Year_base, data = ., family = poisson)
)
poiss_reg_train_int &lt;- suppressWarnings(
  train_collisions %&gt;% 
  glm(Rate ~ 1, data = ., family = poisson)
)
summary(poiss_reg_train)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Rate ~ Year_base, family = poisson, data = .)
## 
## Deviance Residuals: 
##       Min         1Q     Median         3Q        Max  
## -0.074577  -0.032644  -0.006729   0.029501   0.150694  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -3.79488    2.72653  -1.392    0.164
## Year_base   -0.03949    0.19616  -0.201    0.840
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 0.10630  on 28  degrees of freedom
## Residual deviance: 0.06445  on 27  degrees of freedom
## AIC: Inf
## 
## Number of Fisher Scoring iterations: 7</code></pre>
<pre class="r"><code>summary(poiss_reg_train_int)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Rate ~ 1, family = poisson, data = .)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.09341  -0.05297  -0.01480   0.03256   0.15988  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)   -4.294      1.589  -2.702  0.00689 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 0.1063  on 28  degrees of freedom
## Residual deviance: 0.1063  on 28  degrees of freedom
## AIC: Inf
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<pre class="r"><code>anova(poiss_reg_train_int, poiss_reg_train, test = &quot;Chisq&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: Rate ~ 1
## Model 2: Rate ~ Year_base
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1        28    0.10630                     
## 2        27    0.06445  1 0.041849   0.8379</code></pre>
<p>From our <span class="math inline">\(\chi^{2}\)</span> test, our p-value is <span class="math inline">\(&gt;\alpha=0.05\)</span>, so we fail to reject the null hypothesis, that the models explain the same amount of variance, based on the sample. As such, we conclude that the Year exhibits no effect, and our rates are constant.</p>
</div>
<div id="b.-2" class="section level3">
<h3>b.</h3>
<p><span class="math display">\[
  W =
  \frac{-0.0337-0}{0.0130} =
  -2.592308 \sim
  \mathcal{N}(0,1) \implies
  P-Value = 2\min\{\Prob(W \leq -2.592308), \Prob(W \geq -2.592308)\} =
\]</span> <span class="math display">\[
  2\min\{0.004766719, 0.9952333\} =
  0.009533438
\]</span> Since this is <span class="math inline">\(&lt;\alpha=0.05\)</span>, we reject our null hypothesis of <span class="math inline">\(\beta=0\)</span>, and assume the alternative to be true based on the sample.</p>
</div>
<div id="c.-2" class="section level3">
<h3>c.</h3>
<p>95% CI for <span class="math inline">\(\beta\)</span>: <span class="math display">\[
  [-0.060,-0.008]
\]</span> 95% CI for <span class="math inline">\(e^{\beta}\)</span>: <span class="math display">\[
  e^{[-0.060,-0.008]} =
  [0.9417645,0.9920319]
\]</span> That is, with 95% confidence, the true average multiplicative increase for the collision rate as the year increases by 1, is between 0.9417645 and 0.9920319, based on the sample.</p>
</div>
</div>
<div id="section-3" class="section level2">
<h2>4.01</h2>
<div id="a.-3" class="section level3">
<h3>a.</h3>
<p><span class="math display">\[
  \ln\left(\theta\right) =
  -3.7771 + 0.1449x \stackrel{x=8}{\implies}
  \ln\left(\theta\right) =
  -2.6179 \implies
  \hat{\pi} =
  \frac{e^{-2.6179}}{1+e^{-2.6179}} =
  0.068
\]</span></p>
</div>
<div id="b.-3" class="section level3">
<h3>b.</h3>
<p><span class="math display">\[
  \ln\left(\theta\right) =
  -3.7771 + 0.1449x \stackrel{x=26}{\implies}
  \ln\left(\theta\right) =
  -0.0097 \implies
  \hat{\pi} =
  \frac{e^{-0.0097}}{1+e^{-0.0097}} =
  0.4975 \approx
  0.5
\]</span></p>
</div>
<div id="c.-3" class="section level3">
<h3>c.</h3>
<pre class="r"><code>prob &lt;- function(x){exp(-3.7771 + 0.1449*x)/(1 + exp(-3.7771 + 0.1449*x))}
0.1449*prob(8)*(1-prob(8))</code></pre>
<pre><code>## [1] 0.009182588</code></pre>
<pre class="r"><code>0.1449*prob(26)*(1-prob(26))</code></pre>
<pre><code>## [1] 0.03622415</code></pre>
<pre class="r"><code>ggplot(data = tibble(x = c(0, 75)), aes(x)) + 
  stat_function(fun = prob) + 
  labs(y = expression(hat(pi)))</code></pre>
<p><img src="Week_04_Questions_files/figure-html/4.01c-1.png" width="672" /></p>
</div>
<div id="d.-2" class="section level3">
<h3>d.</h3>
<pre class="r"><code>prob(28)</code></pre>
<pre><code>## [1] 0.5695707</code></pre>
<pre class="r"><code>prob(14)</code></pre>
<pre><code>## [1] 0.1482365</code></pre>
<pre class="r"><code>prob(28)-prob(14)</code></pre>
<pre><code>## [1] 0.4213342</code></pre>
</div>
<div id="e." class="section level3">
<h3>e.</h3>
<p><span class="math display">\[
  \frac{\theta(x)}{\theta(x-1)} =
  \frac{e^{-3.7771 + 0.1449(x)}}{e^{-3.7771 + 0.1449(x-1)}} =
  e^{0.1449} =
  1.16
\]</span></p>
</div>
</div>
<div id="section-4" class="section level2">
<h2>4.03</h2>
<div id="a.-4" class="section level3">
<h3>a.</h3>
<p>For each new decade, the probability of a CG for a pitcher falls by 6.94% on average in the NL, based on the sample.</p>
</div>
<div id="b.-4" class="section level3">
<h3>b.</h3>
<p><span class="math display">\[
  \hat{\pi}(12) = 
  0.7578 - 0.0694(12) = 
  -0.075
\]</span> This is not plausible, as <span class="math inline">\(\pi\in[0,1]\)</span>, and -0.075 exists outside of it. As well, this year does not exists in the sample, so it is outside the scope of the regression.</p>
</div>
<div id="c.-4" class="section level3">
<h3>c.</h3>
<p><span class="math display">\[
  \hat{\pi}(12) = 
  \frac{e^{1.148 - 0.315(12)}}{1 + e^{1.148 - 0.315(12)}} =
  0.0671
\]</span> This is more plausible, as it satisfies our restraint on <span class="math inline">\(\pi\)</span>. However, since 12 is not in the sample, this may not accurate.</p>
</div>
</div>
<div id="section-5" class="section level2">
<h2>4.05</h2>
<div id="a.-5" class="section level3">
<h3>a.</h3>
<pre class="r"><code>logit_reg_space &lt;- glm(TD ~ Temp, data = space_results, family = binomial)
summary(logit_reg_space)</code></pre>
<pre><code>## 
## Call:
## glm(formula = TD ~ Temp, family = binomial, data = space_results)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.0611  -0.7613  -0.3783   0.4524   2.2175  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  15.0429     7.3786   2.039   0.0415 *
## Temp         -0.2322     0.1082  -2.145   0.0320 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 28.267  on 22  degrees of freedom
## Residual deviance: 20.315  on 21  degrees of freedom
## AIC: 24.315
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<pre class="r"><code>prob_fun &lt;- function(x){
  predict.glm(logit_reg_space, newdata = data.frame(Temp = x), type = &quot;response&quot;)
}
space_results %&gt;% 
  ggplot(
    aes(
      x = Temp
      ,y = TD
    )
  ) +
  geom_point() +
  stat_smooth(
    method = &quot;glm&quot;
    ,method.args = list(family = &quot;binomial&quot;)
    ,se = FALSE
  ) +
  labs(y = expression(hat(pi)))</code></pre>
<p><img src="Week_04_Questions_files/figure-html/4.05a-1.png" width="672" /></p>
<p>As temperature increase, on average the probability of TD decreases, based on the sample.</p>
</div>
<div id="b.-5" class="section level3">
<h3>b.</h3>
<pre class="r"><code>prob_fun(31)</code></pre>
<pre><code>##         1 
## 0.9996088</code></pre>
</div>
<div id="c.-5" class="section level3">
<h3>c.</h3>
<p><span class="math display">\[
  0.5 =
  \frac{e^{15.0429-0.2322x}}{1+e^{15.0429-0.2322x}} \implies
  \frac{1}{2} \left( 1+e^{15.0429-0.2322x} \right) =
  e^{15.0429-0.2322x} \implies
\]</span> <span class="math display">\[
  1 =
  e^{15.0429-0.2322x} \implies
  0 =
  15.0429-0.2322x \implies
  x = 64.79464
\]</span> More generally: <span class="math display">\[
  x_{0.5} =
  -\frac{\alpha}{\beta}
\]</span></p>
<pre class="r"><code>Temp_median &lt;- -logit_reg_space$coefficients[[1]]/logit_reg_space$coefficients[[2]]
Temp_median</code></pre>
<pre><code>## [1] 64.79464</code></pre>
<pre class="r"><code>prob_fun(Temp_median)</code></pre>
<pre><code>##   1 
## 0.5</code></pre>
</div>
<div id="d.-3" class="section level3">
<h3>d.</h3>
<p>That is, on average, for every unit increase in temperature in Fahrenheit the log odds in favour decrease by -0.2322, or the odds in favour decrease by a multiplicative factor of 0.7927875, based on the sample.</p>
</div>
<div id="e.-1" class="section level3">
<h3>e.</h3>
<div id="i." class="section level4">
<h4>i.</h4>
<p>From above, our p-value for <span class="math inline">\(H_{0}:\beta=0 \text{ vs. } H_{1}:\beta\neq0\)</span> is 0.0320, so at <span class="math inline">\(\alpha=0.05\)</span>, we reject the null hypothesis, and assume the alternative to be true based on the sample.</p>
</div>
<div id="ii." class="section level4">
<h4>ii.</h4>
<pre class="r"><code>logit_reg_space_int &lt;- glm(TD ~ 1, data = space_results, family = binomial)
summary(logit_reg_space_int)</code></pre>
<pre><code>## 
## Call:
## glm(formula = TD ~ 1, family = binomial, data = space_results)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.8519  -0.8519  -0.8519   1.5425   1.5425  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  -0.8267     0.4532  -1.824   0.0681 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 28.267  on 22  degrees of freedom
## Residual deviance: 28.267  on 22  degrees of freedom
## AIC: 30.267
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>anova(logit_reg_space_int, logit_reg_space, test = &quot;Chisq&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: TD ~ 1
## Model 2: TD ~ Temp
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)   
## 1        22     28.267                        
## 2        21     20.315  1    7.952 0.004804 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>From above, our p-value for <span class="math inline">\(H_{0}:\beta=0 \text{ vs. } H_{1}:\beta\neq0\)</span> is 0.004804, so at <span class="math inline">\(\alpha=0.05\)</span>, we reject the null hypothesis, and assume the alternative to be true based on the sample.</p>
</div>
</div>
</div>
<div id="section-6" class="section level2">
<h2>4.07</h2>
<div id="a.-6" class="section level3">
<h3>a.</h3>
<pre class="r"><code>logit_reg_kyph &lt;- glm(Result ~ Age, data = kyphosis, family = binomial)
summary(logit_reg_kyph)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Result ~ Age, family = binomial, data = kyphosis)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.3126  -1.0907  -0.9482   1.2170   1.4052  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -0.572693   0.602395  -0.951    0.342
## Age          0.004296   0.005849   0.734    0.463
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 55.051  on 39  degrees of freedom
## Residual deviance: 54.504  on 38  degrees of freedom
## AIC: 58.504
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Since our p-value for age is <span class="math inline">\(0.463&gt;\alpha=0.05\)</span>, we fail to reject the null hypothesis, based on the sample, and assume age has no effect on the result.</p>
</div>
<div id="b.-6" class="section level3">
<h3>b.</h3>
<pre class="r"><code>kyphosis %&gt;%
  ggplot(
    aes(
      x = Age
      ,y = Result
    )
  ) +
  geom_point() +
  stat_smooth(
    method = &quot;glm&quot;
    ,method.args = list(family = &quot;binomial&quot;)
    ,se = FALSE
  ) +
  labs(y = expression(hat(pi)))</code></pre>
<p><img src="Week_04_Questions_files/figure-html/4.07b-1.png" width="672" /></p>
<p>As you can see, there seems to be no noticable difference in clustering at the tails for each response based on age. As such it’d ake sense we’d see such a low significance for the slope parameter. There is however some clustering near the middle for the Kyphosis results, so there may be an additional explanatory variable needed, or some polynomial term.</p>
</div>
<div id="c.-6" class="section level3">
<h3>c.</h3>
<pre class="r"><code>kyphosis %&lt;&gt;%
  mutate(Age2 = Age^2)
logit_reg_kyph_poly &lt;- glm(Result ~ Age + Age2, data = kyphosis, family = binomial)
summary(logit_reg_kyph_poly)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Result ~ Age + Age2, family = binomial, data = kyphosis)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.482  -1.009  -0.507   1.012   1.788  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept) -2.0462547  0.9943478  -2.058   0.0396 *
## Age          0.0600398  0.0267808   2.242   0.0250 *
## Age2        -0.0003279  0.0001564  -2.097   0.0360 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 55.051  on 39  degrees of freedom
## Residual deviance: 48.228  on 37  degrees of freedom
## AIC: 54.228
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>prob_kyph_poly_fun &lt;- function(x){
  predict(
    object = logit_reg_kyph_poly
    ,newdata = tibble(Age = x, Age2 = x^2)
    ,type = &quot;response&quot;
  )
} 

kyphosis %&gt;% 
  ggplot() +
  geom_point(
    aes(
      x = Age
      ,y = Result
    )
  ) +
  stat_function(
    data = tibble(x = c(0, 200))
    ,aes(x)
    ,fun = prob_kyph_poly_fun
  ) +
  labs(y = expression(hat(pi)))</code></pre>
<p><img src="Week_04_Questions_files/figure-html/4.07c-1.png" width="672" /></p>
<p>This function is maximized at <span class="math inline">\(\approx 91.552\)</span>, so at Age in months increases up until that point, the probability on average increases, based on the sample. Afterwards as Age increases above that point, on average the probability decreases, based on the sample.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
