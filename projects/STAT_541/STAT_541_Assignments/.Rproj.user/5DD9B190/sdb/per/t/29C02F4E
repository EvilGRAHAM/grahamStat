{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Week 06 Questions\"\nauthor: \"Scott Graham\"\ndate: \"October 20, 2017\"\noutput:\n  html_document:\n    theme: lumen\n    toc: true\n    toc_depth: 2\n    toc_float: true\n    code_folding: hide\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse, warn.conflicts = FALSE, quietly = TRUE)\nlibrary(magrittr, warn.conflicts = FALSE, quietly = TRUE)\ntheme_minimal2 <- theme_minimal() %>%  theme_set()\ntheme_minimal2 <-\n  theme_update(\n    panel.border = element_rect(\n      linetype = \"solid\"\n      ,colour = \"grey92\"\n      ,fill = NA\n    )\n    ,strip.background = element_rect(\n      linetype = \"solid\"\n      ,colour = \"grey92\"\n      ,fill = NA\n    )\n  )\n```\n\\[\n  \\newcommand{\\Prob}{\\operatorname{P}}\n  \\newcommand{\\E}{\\operatorname{E}}\n  \\newcommand{\\Var}{\\operatorname{Var}}\n  \\newcommand{\\Cov}{\\operatorname{Cov}}\n  \\newcommand{\\se}{\\operatorname{se}}\n  \\newcommand{\\re}{\\operatorname{re}}\n  \\newcommand{\\ybar}{{\\overline{Y}}}\n  \\newcommand{\\phat}{{\\hat{p}}}\n  \\newcommand{\\that}{{\\hat{T}}}\n  \\newcommand{\\med}{{\\tilde{Y}}}\n\\]\n\n## 4.23\n### a.\n$$\n  \\ln(\\theta) =\n  \\begin{cases}\n    -7.00 + 0.10A + 1.20S \\text{, if } R = 0  \\\\\n    -6.70 + 0.10A + 1.40S \\text{, if } R = 1\n  \\end{cases}\n$$\n$$\n  OR_{YS} =\n  \\begin{cases}\n    e^{1.20} = 3.3201 \\text{, if } R = 0  \\\\\n    e^{1.40} = 4.0552 \\text{, if } R = 1\n  \\end{cases}\n$$\n$$\n  \\ln(\\theta) =\n  \\begin{cases}\n    -7.00 + 0.10A + 0.30R \\text{, if } S = 0  \\\\\n    -5.80 + 0.10A + 0.50R \\text{, if } S = 1\n  \\end{cases}\n$$\n$$\n  OR_{YR} =\n  \\begin{cases}\n    e^{0.30} = 1.3499 \\text{, if } S = 0  \\\\\n    e^{0.50} = 1.6487 \\text{, if } S = 1\n  \\end{cases}\n$$\n\n### b.\nThose coefficients represent the average additive increase in the log odds in favour, when the other variable is set to 0, based on the sample. i.e. There is a 1.20 increase on average in the log odds in favour for a white person, when they smoke at least on pack a day, and a 0.30 increase on average in the log odds in favour for a person who smokes at lease one pack a day, when they are black. \n\nThe p-values are testing:\n$$\n  H_{0}: \\beta_{i} = 0\n$$\n$$\n  H_{1}: \\beta_{i} \\neq 0\n$$\nfor a given i.\n\n### c.\n$$\n  \\ln(\\theta) =\n  \\begin{cases}\n    -7.00 + 0.10A + 1.20S \\text{, if } R = 0  \\\\\n    -6.70 + 0.14A + 1.40S \\text{, if } R = 1\n  \\end{cases}\n$$\n\n\n## 4.26\n### a.\n$$\n  \\ln(\\theta) =\n  -12.715 + 1.106(1) + 0.468(20) =\n  -2.249 \\implies\n  \\Prob(Y = 1 | X) =\n  \\frac{e^{-2.249}}{1 + e^{-2.249}} =\n  0.0954\n$$\n$$\n  \\ln(\\theta) =\n  -12.715 + 0.468(20) =\n  -3.355 \\implies\n  \\Prob(Y = 1 | X) =\n  \\frac{e^{-3.355}}{1 + e^{-3.355}} =\n  0.0337\n$$\n$$\n  \\implies\n  \\frac{0.0954}{0.0337} =\n  2.8293\n$$\n\n### b.\n$$\n  \\theta =\n  e^{-12.715 + 1.106(1) + 0.468(20)} =\n  0.1055\n$$\n$$\n  \\theta =\n  e^{-12.715 + 0.468(20)} =\n  0.0349\n$$\n$$\n  \\implies\n  OR =\n  \\frac{0.1055}{0.0349} =\n  3.0222 \\implies\n  \\ln(3.0222) =\n  1.106\n$$\n\nTherefore the odds ratio is on average equal to the $e^{\\beta_{i}}$ of the differing parameter between the two predictions.\n\n\n## 4.27\n### a.\n$$\n  \\sigma_{c} = \n  0.80 \\implies\n  \\sigma_{c} \\hat{\\beta}_{c} =\n  0.80(-0.509) =\n  -0.4072\n$$\n$$\n  \\sigma_{x} = \n  2.11 \\implies\n  \\sigma_{x} \\hat{\\beta}_{x} =\n  2.11(0.458) =\n  0.9664\n$$\n\nThus for every 1 sd increase in colour, the odds in favour increase on average by a multiplicative factor of 0.6655. For every 1 sd increase in width, the odds in favour increase on average by a multiplicative factor of 2.6284. Both of these are based on the sample.\n\n### b.\n```{r 4.27b}\nlogit_crab_4.27 <- function(colour, weight){\n  -10.071 - 0.509*colour + 0.458*weight\n}\nprob_crab_4.27 <- function(colour, weight){\n  exp(logit_crab_4.27(colour, weight))/(1 + exp(logit_crab_4.27(colour, weight)))\n}\ncolour <- 1:4\nweight <- c(24.9, 27.7)\nresults_crab <- tibble(\n  colour = as.numeric()\n  ,weight = as.numeric()\n  ,probability = as.numeric()\n)\nresults_crab_row <- 1\nfor (i in colour){\n  for (j in weight){\n    results_crab[results_crab_row,] <- cbind(i, j, prob_crab_4.27(colour = i, weight = j))\n    results_crab_row <- results_crab_row + 1\n  }\n}\nresults_crab\n```\n\nFor changes over the middle 50\\% of width, there is a greater change on average in probability than there is for each unit increase in colour. \n\n\n## 4.30\n```{r 4.30 01}\ngrad_data_summary <- \n  tibble(\n    Race = rep(c(\"W\", \"B\"), each = 2)\n    ,Gender = rep(c(\"F\", \"M\"), times = 2)\n    ,`Sample Size` = \n      c(\n        796\n        ,1625\n        ,143\n        ,660\n      )\n    ,Graduates =\n      c(\n        498\n        ,878\n        ,54\n        ,197\n      )\n  ) %>% \n  mutate(\n    `Drop Outs` = `Sample Size` - Graduates\n    ,Proportion = Graduates / `Sample Size`\n  )\n\ngrad_data <- \n  tibble(\n    Race = \n      rep(\n        c(\"B\", \"W\")\n        ,times =\n          (grad_data_summary %>%\n             group_by(Race) %>% \n             dplyr::select(\n               Race\n               ,`Sample Size`\n               ,Graduates\n               ,`Drop Outs`\n               ,Proportion\n             ) %>%\n             summarise_all(sum)\n           )$`Sample Size`\n      )\n    ,Gender = \n      c(\n        rep(\n          c(\"F\", \"M\")\n          ,times =\n            (grad_data_summary %>%\n               filter(Race == \"B\")\n             )$`Sample Size`\n        )\n        ,rep(\n          c(\"F\", \"M\")\n          ,times =\n            (grad_data_summary %>%\n               filter(Race == \"W\")\n             )$`Sample Size`\n        )\n      )\n    ,Graduated = \n      c(\n        rep(\n          0:1\n          ,times =\n            c(\n              (grad_data_summary %>%\n                 filter(Race == \"B\", Gender == \"F\")\n               )$`Drop Outs`\n              ,(grad_data_summary %>%\n                 filter(Race == \"B\", Gender == \"F\")\n               )$Graduates\n            )\n        )\n        ,rep(\n          0:1\n          ,times =\n            c(\n              (grad_data_summary %>%\n                 filter(Race == \"B\", Gender == \"M\")\n               )$`Drop Outs`\n              ,(grad_data_summary %>%\n                 filter(Race == \"B\", Gender == \"M\")\n               )$Graduates\n            )\n        )\n        ,rep(\n          0:1\n          ,times =\n            c(\n              (grad_data_summary %>%\n                 filter(Race == \"W\", Gender == \"F\")\n               )$`Drop Outs`\n              ,(grad_data_summary %>%\n                 filter(Race == \"W\", Gender == \"F\")\n               )$Graduates\n            )\n        )\n        ,rep(\n          0:1\n          ,times =\n            c(\n              (grad_data_summary %>%\n                 filter(Race == \"W\", Gender == \"M\")\n               )$`Drop Outs`\n              ,(grad_data_summary %>%\n                 filter(Race == \"W\", Gender == \"M\")\n               )$Graduates\n            )\n        )\n    )\n  )\nlogit_grads <- glm(Graduated ~ Race + Gender, data = grad_data, family = binomial)\nsummary(logit_grads)\n```\n\nLet:\n$$\n  Y_{i} =\n  \\begin{cases}\n    0 \\text{, if i didn't graduate} \\\\\n    1 \\text{, if i didn't graduate}\n  \\end{cases}\n$$\n$$\n    R_{i} =\n  \\begin{cases}\n    0 \\text{, if i is black} \\\\\n    1 \\text{, if i is white}\n  \\end{cases}\n$$\n$$\n  G_{i} =\n  \\begin{cases}\n    0 \\text{, if i is female} \\\\\n    1 \\text{, if i is male}\n  \\end{cases}\n$$\n\nThen:\n$$\n  \\ln\\left( \\theta_{i} \\right) =\n  -0.5016 + 1.0155R_{i} - 0.3524G_{i}\n$$\n```{r 4.30 02}\nlogit_grads %>% \n  coef %>% \n  exp %>% \n  round(4)\n```\nOn average, the odds increases by a multiplicative factor of $e^{1.0155}=2.7606$ if someone is white vs. black, based on the sample. On average, the odds decreases by a multiplicative factor of $e^{-0.3524}=0.7030$ if someone is male vs. female, based on the sample. All the coefficients are also deemed to be highly significant.\n```{r 4.30 03}\ngrad_data_summary %<>% \n  mutate(\n    `Predicted Proportion` =\n      predict(\n        logit_grads\n        ,newdata = \n          grad_data_summary %>% \n          dplyr::select(Race, Gender)\n        ,type = \"response\"\n      )\n  )\ngrad_data_summary %>% \n  dplyr::select(-c(`Sample Size`, Graduates, `Drop Outs`))\n```\n\n\n## 4.36\n```{r 4.36}\nlogit_crab_4.36 <- function(weight){\n  -12.351 + 0.497*weight\n}\nprob_crab_4.36 <- function(weight){\n  exp(logit_crab_4.36(weight))/(1 + exp(logit_crab_4.36(weight)))\n}\n```\n### a.\n```{r 4.36a}\nggplot(\n  data = tibble(weight = c(0, 50))\n  ,aes(weight)\n) +\n  stat_function(fun = prob_crab_4.36) +\n  labs(\n    x = \"Weight\"\n    ,y = expression(hat(pi))\n  )\n```\n$$\n  \\mu =\n  -\\frac{-12.351}{0.497} =\n  24.8511\n$$\n$$\n  \\sigma =\n  \\frac{1.814}{0.497} =\n  3.6499\n$$\n\n### b.\n$$\n  \\mu \\mp 2\\sigma =\n  24.8511 \\mp 2(3.6499) =\n  [17.5513, 32.1509]\n$$\n```{r 4.36b}\n(12.351/0.497 + 2 * 1.814/0.497*c(-1,1)) %>% \n  prob_crab_4.36 %>% \n  round(4)\n```\n\n\n## 5.01\n```{r 5.01}\ncrabs_data <- \n  read_csv(\n    file = \"http://grahamst.at/projects/STAT_541/STAT_541_Assignments/Week_06_Data_5.01.csv\"\n  ) %>%\n  mutate(\n    satell_bool = if_else(satell > 0, 1, 0)\n    ,weight = weight/1000\n  )\n```\n### a.\n```{r 5.01a}\nlogit_crab_5.01 <- \n  crabs_data %>% \n  glm(\n    satell_bool ~ weight + width\n    ,data = .\n    ,family = binomial\n  )\nsummary(logit_crab_5.01)\n```\n\n$$\n  \\ln(\\theta) =\n  -9.3547 + 0.8338Weight + 0.3068Width\n$$\n\n### b.\n```{r 5.01b}\nlogit_crab_5.01b <- \n  crabs_data %>% \n  glm(\n    satell_bool ~ 1\n    ,data = .\n    ,family = binomial\n  )\nanova(logit_crab_5.01b, logit_crab_5.01, test = \"Chisq\")\n```\n$$\n  H_{0}: \\beta_{i} = 0, \\forall i = 1,2\n$$\n$$\n  H_{1}: \\beta_{i} \\neq 0, \\exists i = 1,2\n$$\nAnd with a p-value of $7.296*10^{-8}$ under the null hypothesis, the null hypothesis is reject, and the alternative is accepted based on the sample.\n\n### c.\n```{r 5.01c}\nlogit_crab_5.01weight <- \n  crabs_data %>% \n  glm(\n    satell_bool ~ weight\n    ,data = .\n    ,family = binomial\n  )\nlogit_crab_5.01width <- \n  crabs_data %>% \n  glm(\n    satell_bool ~ width\n    ,data = .\n    ,family = binomial\n  )\nanova(logit_crab_5.01weight, logit_crab_5.01, test = \"Chisq\")\nanova(logit_crab_5.01width, logit_crab_5.01, test = \"Chisq\")\ncor(x = crabs_data$weight, crabs_data$width)\n```\nBecause width and weight have a correlation of 88.69\\%, a high degree of colinearity exists. When testing they both $=0$, vs at least one days, the test doesn't distinguish which one is a better predictor, just that at least one of them is non-zero. When we are testing whether or not we can remove one of them, without serverely impacting the explained variance, we are testing that the missing predictor $=0$, and because of this, we can remove one due to their high correlation.",
    "created" : 1509062656035.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "367304038",
    "id" : "29C02F4E",
    "lastKnownWriteTime" : 1509063361,
    "last_content_update" : 1509063361823,
    "path" : "~/GitHub/grahamStat/projects/STAT_541/STAT_541_Assignments/Week_06_Questions.Rmd",
    "project_path" : "Week_06_Questions.Rmd",
    "properties" : {
        "last_setup_crc32" : ""
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}